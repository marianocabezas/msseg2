{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "constant-present",
   "metadata": {},
   "source": [
    "# Notebook to evaluate the activity model\n",
    "\n",
    "This notebook is designed as an evaluation notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aging-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "import ants\n",
    "import pandas as pd\n",
    "import statsmodels.api as smapi\n",
    "import numpy as np\n",
    "from nibabel import load as load_nii\n",
    "from nibabel import Nifti1Image\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import label as bwlabeln\n",
    "from scipy.ndimage.morphology import binary_erosion\n",
    "from scipy.ndimage.morphology import binary_dilation\n",
    "from scipy.ndimage.morphology import binary_closing\n",
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "from scipy.stats import ttest_rel, normaltest\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "from shutil import copyfile\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-belarus",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "white-sister",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation(metrics, network, lowess=False):\n",
    "    model_vols = [m[5] for m in metrics['positive'] if m[1] == network]\n",
    "    manual_vols = [m[6] for m in metrics['positive'] if m[1] == network]\n",
    "    model_lesions = [m[10] for m in metrics['positive'] if m[1] == network]\n",
    "    manual_lesions = [m[11] for m in metrics['positive'] if m[1] == network]\n",
    "    array = [\n",
    "        [\n",
    "            (m[6] - np.mean(manual_vols)) / np.std(manual_vols),\n",
    "            (m[5] - np.mean(model_vols)) / np.std(model_vols),\n",
    "            'Volume'\n",
    "        ]\n",
    "        for m in metrics['positive'] if m[1] == network\n",
    "    ] + [\n",
    "        [\n",
    "            (m[11] - np.mean(manual_lesions)) / np.std(manual_lesions),\n",
    "            (m[10] - np.mean(model_lesions)) / np.std(model_lesions),\n",
    "            'Lesions'\n",
    "        ]\n",
    "        for m in metrics['positive'] if m[1] == network\n",
    "    ]\n",
    "\n",
    "    columns = [\n",
    "        'Manual',\n",
    "        'Model',\n",
    "        'Value per patient'\n",
    "    ]\n",
    "    dataframe = pd.DataFrame(array, columns=columns)\n",
    "\n",
    "    snd_handle = sns.lmplot(\n",
    "        x='Model', y='Manual', data=dataframe, hue='Value per patient',\n",
    "        ci=68, truncate=False, lowess=lowess, robust=(not lowess)\n",
    "    ) \n",
    "    \n",
    "    lesions_dataframe = dataframe[dataframe['Value per patient'] == 'Lesions']\n",
    "    x = lesions_dataframe['Model'].to_numpy()\n",
    "    y = lesions_dataframe['Manual'].to_numpy()\n",
    "    \n",
    "    x[np.isnan(x)] = 0\n",
    "    y[np.isnan(y)] = 0\n",
    "    \n",
    "    results_lesions = smapi.OLS(y, smapi.add_constant(x)).fit()\n",
    "    spr_lesions, _ = spearmanr(x, y)\n",
    "    \n",
    "    volume_dataframe = dataframe[dataframe['Value per patient'] == 'Volume']\n",
    "    x = volume_dataframe['Model'].to_numpy()\n",
    "    y = volume_dataframe['Manual'].to_numpy()\n",
    "    \n",
    "    x[np.isnan(x)] = 0\n",
    "    y[np.isnan(y)] = 0\n",
    "    \n",
    "    results_volume = smapi.OLS(y, smapi.add_constant(x)).fit()\n",
    "    spr_volume, _ = spearmanr(x, y)\n",
    "\n",
    "    if lowess:\n",
    "        plt.title(\n",
    "            u'{:} Lesions [\\u03C1 = {:5.3f}] / Volume [\\u03C1 = {:5.3f}]'.format(\n",
    "                network, spr_lesions, spr_volume     \n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        plt.title(\n",
    "            u'{:} Lesions [R\\u00b2 = {:5.3f}] / Volume [R\\u00b2 = {:5.3f}]'.format(\n",
    "                network,\n",
    "                results_lesions.rsquared,\n",
    "                results_volume.rsquared     \n",
    "            )\n",
    "        )\n",
    "    snd_handle.fig.subplots_adjust(top=.95, bottom=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-chinese",
   "metadata": {},
   "source": [
    "### Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "grave-travel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_int(string):\n",
    "    \"\"\"\n",
    "    Function to get the int number contained in a string. If there are more\n",
    "    than one int number (or there is a floating point number), this function\n",
    "    will concatenate all digits and return an int, anyways.\n",
    "    :param string: String that contains an int number\n",
    "    :return: int number\n",
    "    \"\"\"\n",
    "    return int(''.join(filter(str.isdigit, string)))\n",
    "\n",
    "\n",
    "def get_dirs(path):\n",
    "    \"\"\"\n",
    "    Function to get the folder name of the patients given a path.\n",
    "    :param path: Folder where the patients should be located.\n",
    "    :return: List of patient names.\n",
    "    \"\"\"\n",
    "    # All patients (full path)\n",
    "    patient_paths = sorted(\n",
    "        filter(\n",
    "            lambda d: os.path.isdir(os.path.join(path, d)),\n",
    "            os.listdir(path)\n",
    "        )\n",
    "    )\n",
    "    # Patients used during training\n",
    "    return patient_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-raising",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "harmful-saint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['013', '015', '016', '018', '019', '020', '021', '024', '026', '027', '029', '030', '032', '035', '037', '039', '043', '047', '048', '049', '051', '052', '057', '061', '068', '069', '070', '074', '077', '083', '084', '088', '089', '090', '091', '094', '095', '096', '099', '100']\n"
     ]
    }
   ],
   "source": [
    "path = '/media/transcend/MSReports/Longitudinal/MICCAI_Challenge2021/training/'\n",
    "cases = [\n",
    "    p for p in sorted(os.listdir(path))\n",
    "    if os.path.isdir(os.path.join(path, p))\n",
    "]\n",
    "print(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d765662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive cases ['013', '016', '018', '020', '021', '024', '026', '027', '029', '030', '032', '035', '037', '039', '043', '047', '048', '057', '061', '069', '074', '077', '083', '088', '091', '094', '095', '099', '100']\n",
      "Negative cases ['015', '019', '049', '051', '052', '068', '070', '084', '089', '090', '096']\n"
     ]
    }
   ],
   "source": [
    "positive_cases = []\n",
    "negative_cases = []\n",
    "for p in cases:\n",
    "    p_path = os.path.join(path, p)\n",
    "    print('\\033[KChecking {:}'.format(p_path), end='\\r')\n",
    "    gt_bool = load_nii(\n",
    "        os.path.join(p_path, 'ground_truth.nii.gz')\n",
    "    ).get_fdata().astype(bool)\n",
    "    if np.sum(gt_bool) > 0:\n",
    "        positive_cases.append(p)\n",
    "    else:\n",
    "        negative_cases.append(p)\n",
    "print('Positive cases', positive_cases)\n",
    "print('Negative cases', negative_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-athletics",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "### Loading and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "theoretical-wells",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KChecking /media/transcend/MSReports/Longitudinal/MICCAI_Challenge2021/training/030\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9057847e2827>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0;31m# And finally a few regionwise / detection metrics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mtp_labs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_lab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mauto_bool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mnotfp_labs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauto_lab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgt_bool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfp_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauto_lab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotfp_labs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_metrics = {\n",
    "    'positive': [],\n",
    "    'negative': []\n",
    "}\n",
    "manual_vols = []\n",
    "model_vols = []\n",
    "manual_lesions = []\n",
    "model_lesions = []\n",
    "positive_metrics = [\n",
    "    'Patient', 'Network',\n",
    "    'TPF (V)', 'FPF (V)', 'DSC', 'TP (V)', 'V','GT (V)',\n",
    "    'TPF (D)', 'FPF (D)', 'TP (D)', 'D', 'GT (D)', 'TP (C)'\n",
    "]\n",
    "negative_metrics = [\n",
    "    'Patient', 'Network',\n",
    "    'FP (V)', 'FP (D)', 'FP (C)'\n",
    "]\n",
    "training_labels = {\n",
    "    '': 'Baseline',\n",
    "    '_ft': 'Fine-tuning',\n",
    "    '_ft-freeze': 'Fine-tuning (frozen)',\n",
    "    '_xval': 'Trained',\n",
    "}\n",
    "with open(\n",
    "        os.path.join(path, 'activity_metrics.csv'), 'w'\n",
    ") as csvfile:\n",
    "    evalwriter = csv.writer(csvfile)\n",
    "    evalwriter.writerow(positive_metrics)\n",
    "    for p in cases:\n",
    "        p_path = os.path.join(path, p)\n",
    "        print('\\033[KChecking {:}'.format(p_path), end='\\r')\n",
    "        gt_bool = load_nii(\n",
    "            os.path.join(p_path, 'ground_truth.nii.gz')\n",
    "        ).get_fdata().astype(bool)\n",
    "        gt_lab = bwlabeln(gt_bool)\n",
    "        gt_v = np.sum(gt_bool)\n",
    "        gt_d = len(np.unique(gt_lab[gt_lab > 0]))\n",
    "        gtc = gt_v > 0\n",
    "        \n",
    "        for tr_key, tr_value in training_labels.items():\n",
    "            auto_name = os.path.join(\n",
    "                p_path, 'positive_activity{:}.nii.gz'.format(tr_key)\n",
    "            )\n",
    "            auto_bool = load_nii(auto_name).get_fdata().astype(bool)\n",
    "            auto_lab = bwlabeln(auto_bool)\n",
    "            auto_labs = np.unique(auto_lab)\n",
    "            \n",
    "            v = np.sum(auto_bool)\n",
    "\n",
    "            # Positive cases\n",
    "            if gtc:\n",
    "                # Some intermediate steps.\n",
    "                overlap = np.logical_and(gt_bool, auto_bool)\n",
    "                nonoverlap = np.logical_and(np.logical_not(gt_bool), auto_bool)\n",
    "                               \n",
    "                # Pretty common and normal voxelwise / segmentation metrics.\n",
    "                sum_v = v + gt_v\n",
    "                \n",
    "                tp_v = np.sum(overlap)\n",
    "                tpf_v = tp_v / gt_v if gt_v > 0 else 0\n",
    "                fp_v = np.sum(nonoverlap)\n",
    "                fpf_v = fp_v / v if v > 0 else 0\n",
    "                dsc = 2 * tp_v / sum_v if sum_v > 0 else 0\n",
    "\n",
    "                # And finally a few regionwise / detection metrics.\n",
    "                tp_labs = np.unique(gt_lab[auto_bool])\n",
    "                notfp_labs = np.unique(auto_lab[gt_bool])\n",
    "                fp_mask = np.logical_not(np.isin(auto_lab, notfp_labs))\n",
    "                fp_labs = np.unique(auto_lab[fp_mask])\n",
    "                tp = len(tp_labs[tp_labs > 0])\n",
    "                tp_d = len(tp_labs[tp_labs > 0])\n",
    "                fp = len(fp_labs[fp_labs > 0])\n",
    "                tpf_d = 100 * tp / gt_d if gt_d > 0 else 0\n",
    "                d = len(np.unique(auto_lab[auto_lab > 0]))\n",
    "                fpf_d = 100 * fp / d if d > 0 else 0\n",
    "\n",
    "                tpc = v > 0\n",
    "\n",
    "                all_metrics['positive'].append([\n",
    "                    p, tr_value, tpf_v, fpf_v, dsc, tp_v, v, gt_v,\n",
    "                    tpf_d, fpf_d, tp_d, d, gt_d, tpc\n",
    "                ])\n",
    "                evalwriter.writerow([\n",
    "                    p, tr_value, tpf_v, fpf_v, dsc, tp_v, v, gt_v,\n",
    "                    tpf_d, fpf_d, tp_d, d, gt_d, tpc\n",
    "                ])\n",
    "            else:\n",
    "                # And finally a few regionwise / detection metrics.\n",
    "                fp_d = len(auto_labs[auto_labs > 0])\n",
    "                fp_c = fp_d > 0\n",
    "                fp_v = v\n",
    "\n",
    "                all_metrics['negative'].append([\n",
    "                    p, tr_value, fp_v, fp_d, fp_c\n",
    "                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-bailey",
   "metadata": {},
   "source": [
    "### Patient-based metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(all_metrics['positive'], columns=positive_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9b6b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df = pd.DataFrame(all_metrics['positive'], columns=positive_metrics)\n",
    "positive_df[positive_df['DSC'] < 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b91068",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df[positive_df['Network'] == 'Trained']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d722c78b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(all_metrics['negative'], columns=negative_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f2a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_df = pd.DataFrame(all_metrics['negative'], columns=negative_metrics)\n",
    "negative_df[negative_df['FP (C)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-briefing",
   "metadata": {},
   "source": [
    "### Mean metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df = pd.DataFrame(all_metrics['positive'], columns=positive_metrics)\n",
    "positive_df.groupby('Network', sort=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dd0a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df[positive_df['DSC'] > 0.6].groupby('Network', sort=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8c73b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df[positive_df['DSC'] > 0.6].groupby('Network', sort=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a966c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_df = pd.DataFrame(all_metrics['negative'], columns=negative_metrics)\n",
    "negative_df.groupby('Network', sort=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-authority",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-accuracy",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_correlation(all_metrics, 'Baseline')\n",
    "plot_correlation(all_metrics, 'Baseline', lowess=True)\n",
    "plot_correlation(all_metrics, 'Fine-tuning')\n",
    "plot_correlation(all_metrics, 'Fine-tuning', lowess=True)\n",
    "plot_correlation(all_metrics, 'Fine-tuning (frozen)')\n",
    "plot_correlation(all_metrics, 'Fine-tuning (frozen)', lowess=True)\n",
    "plot_correlation(all_metrics, 'Trained')\n",
    "plot_correlation(all_metrics, 'Trained', lowess=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-tourist",
   "metadata": {},
   "source": [
    "## Evaluation on the testing set (~100 cases)\n",
    "\n",
    "The results of this experiment will serve to test the best post-processing based on the following ideas:\n",
    "- Constraining positive activity to the follow-up lesion mask (detected lesions)\n",
    "- Constraining positive activity based on the baseline mask (remove activity from detected lesions)\n",
    "- Improving the brain mask (Geng's model)\n",
    "- Eroding the brain mask to reduce \"boundary lesions\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-edwards",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
